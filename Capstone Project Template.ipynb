{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline using I94 immigration data and US cities demographics data to combine the two databases to display immigration events. This database can be used to answer questions relating immigration and the population of each city and states in the US such as: what are the cities with high population?\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from pyspark.sql.types import IntegerType\n",
    "from os.path import isfile, join\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,udf\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project, spark will be used to preocess the data which I94 immigration data will be aggregated by destination city to form our first dimension table, and  the US cities demographics data will be aggregted by city to form the second dimension table. The two datasets will be joined on destination city to form the fact table. The final database is optimized to query on immigration events to show the population and the number of Foreign-born.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "SAS7BDAT database format of the I94 immigration data comes from the US National Tourism and Trade Office and the following data was used in this project:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = month in numbers\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination USA city\n",
    "* arrdate = arrival date in the USA\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date from the USA\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "\n",
    "\n",
    "The cities demographics data comes from Kaggle, it is provided in csv format, and the following categries were used:\n",
    "* City = city name\n",
    "* State = Satate Name\n",
    "* Total Population = total number of population in the city\n",
    "* Foreign-born = number of foreign born\n",
    "* State Code = ISO state code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i94_apr16_sub.sas7bdat', 'i94_sep16_sub.sas7bdat', 'i94_nov16_sub.sas7bdat', 'i94_mar16_sub.sas7bdat', 'i94_jun16_sub.sas7bdat', 'i94_aug16_sub.sas7bdat', 'i94_may16_sub.sas7bdat', 'i94_jan16_sub.sas7bdat', 'i94_oct16_sub.sas7bdat', 'i94_jul16_sub.sas7bdat', 'i94_feb16_sub.sas7bdat', 'i94_dec16_sub.sas7bdat']\n"
     ]
    }
   ],
   "source": [
    "#Listing All I94 immigration files in the Directory \n",
    "dirName = '../../data/18-83510-I94-Data-2016'\n",
    "fileNames = [f for f in listdir(dirName) if isfile(join(dirName, f))]\n",
    "print (fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save May 2016 I94 immigration data into Pandas\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat'\n",
    "immigration_df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3444249, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.141634e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20598.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>05232018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.863211e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>11032016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.696371e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.141260e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EK</td>\n",
       "      <td>6.479287e+10</td>\n",
       "      <td>00235</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    2.0  2016.0     5.0   207.0   207.0     XXX  20605.0      NaN     NaN   \n",
       "1    3.0  2016.0     5.0   209.0   209.0     XXX  20598.0      NaN     NaN   \n",
       "2    4.0  2016.0     5.0   213.0   213.0     XXX  20578.0      NaN     NaN   \n",
       "3    5.0  2016.0     5.0   213.0   213.0     XXX  20601.0      NaN     NaN   \n",
       "4   13.0  2016.0     5.0   213.0   213.0     CHI  20577.0      1.0      IL   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1989.0       D/S    NaN    NaN   \n",
       "1      NaN   ...           U      NaN   1989.0  05232018    NaN    NaN   \n",
       "2      NaN   ...           U      NaN   1938.0  11032016    NaN    NaN   \n",
       "3      NaN   ...           U      NaN   1987.0       D/S    NaN    NaN   \n",
       "4  20270.0   ...         NaN        M   1987.0       D/S      F    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.141634e+09    NaN       F1  \n",
       "1     NaN  1.863211e+09    NaN       E2  \n",
       "2     NaN  4.696371e+09    NaN       B2  \n",
       "3     NaN  1.141260e+09    NaN       F1  \n",
       "4      EK  6.479287e+10  00235       F1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe and display the df of May 2016 I94 immigration data\n",
    "print(immigration_df.shape)\n",
    "immigration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#immigration_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the US cities demographics data into Pandas\n",
    "city_df = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "# Describe and display the df of US cities demographics data\n",
    "print(city_df.shape)\n",
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session with SAS7BDAT jar\n",
    "spark = SparkSession\\\n",
    ".builder \\\n",
    ".config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Create Spark session for csv\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "For the I94 immigration data, we want to drop all entries of i94port as described in I94_SAS_Labels_Description.SAS for the destination city code with no port code, unknown (XXX, ..etc.), no port code as(CHN), collapsed code and considering the i94cit & i94res with valid value and making sure that it is not including the invaled values as (239,700,..etc), collapsed as (311,...etc), and without counrty code as (100,300,..etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data function\n",
    "editing = re.compile(r'[\\s+\\n\\r\\t\\']')\n",
    "i94port_cleaned = {}\n",
    "i94cit_cleaned = {}\n",
    "\n",
    "#cleaning i94port.txt\n",
    "with open('i94port.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        editedport = editing.sub(\"\", line)\n",
    "        (key1, val1) = editedport.split(\"=\")\n",
    "        i94port_cleaned[key1] = val1\n",
    "        \n",
    "#cleaning i94cit.txt\n",
    "with open('i94cit.txt', 'r') as f2:\n",
    "    for line2 in f2:\n",
    "        edited2 = editing.sub(\"\", line2)\n",
    "        (key2, val2) = edited2.split(\"=\")\n",
    "        i94cit_cleaned[key2] = val2\n",
    "#list(i94cit_i94res_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing additional words for cleaning \n",
    "for val1 in i94port_cleaned.values():\n",
    "    val1 = val1.replace('(BPS)', '')\n",
    "    val1 = val1.replace('#ARPT', '') \n",
    "    val1 = val1.replace('(I-91)', '')\n",
    "    val1 = val1.replace('(RT.5)', '')\n",
    "    val1 = val1.replace('(BP-SECTORHQ)', '')\n",
    "    val1 = val1.replace('#INTL', '')\n",
    "    i94port_cleaned[key1] = val1\n",
    "    \n",
    "#print(i94port_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_i94_data(file):\n",
    "    '''\n",
    "    Input: Path to I94 immigration data file\n",
    "    Output: Spark dataframe with I94 immigration data filtered with the i94port\n",
    "    '''\n",
    "    \n",
    "    # Read I94 data into Spark\n",
    "    df_immig_filtered = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    df_immig_filtered = df_immig_filtered.withColumn(\"i94cit\", df_immig_filtered[\"i94cit\"].cast(IntegerType()))\n",
    "    \n",
    "    # Filter out i94port & i94cit\n",
    "    df_immig_filtered1 = df_immig_filtered.filter(df_immig_filtered.i94port.isin(list(i94port_cleaned.keys())))\n",
    "    df_immig_filtered2 = df_immig_filtered1.filter(df_immig_filtered1.i94cit.isin(list(i94cit_cleaned.keys())))\n",
    "    return df_immig_filtered2\n",
    "\n",
    "# Testing \n",
    "# fname is the '../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat' \n",
    "#df_test = clean_i94_data(fname)\n",
    "#df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Demographics Data\n",
    "For the US cities demographics data, the male and female populations were added to make sure having the right total population, and the Number of Veteransit seems & Foreign-bornthat should be less than or equal to the total population. It seems that the data is cleaned, and no big changes are required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+----------------+------------+\n",
      "|            City|         State|State Code|Total_Population|Foreign-born|\n",
      "+----------------+--------------+----------+----------------+------------+\n",
      "|   Silver Spring|      Maryland|        MD|           82463|       30908|\n",
      "|          Quincy| Massachusetts|        MA|           93629|       32935|\n",
      "|          Hoover|       Alabama|        AL|           84839|        8229|\n",
      "|Rancho Cucamonga|    California|        CA|          175232|       33878|\n",
      "|          Newark|    New Jersey|        NJ|          281913|       86253|\n",
      "|          Peoria|      Illinois|        IL|          118661|        7517|\n",
      "|        Avondale|       Arizona|        AZ|           80683|        8355|\n",
      "|     West Covina|    California|        CA|          108489|       37038|\n",
      "|        O'Fallon|      Missouri|        MO|           85032|        3269|\n",
      "|      High Point|North Carolina|        NC|          109828|       16315|\n",
      "|          Folsom|    California|        CA|           76368|       13234|\n",
      "|          Folsom|    California|        CA|           76368|       13234|\n",
      "|    Philadelphia|  Pennsylvania|        PA|         1567442|      205339|\n",
      "|         Wichita|        Kansas|        KS|          389955|       40270|\n",
      "|         Wichita|        Kansas|        KS|          389955|       40270|\n",
      "|      Fort Myers|       Florida|        FL|           74015|       15365|\n",
      "|      Pittsburgh|  Pennsylvania|        PA|          304385|       28187|\n",
      "|          Laredo|         Texas|        TX|          255789|       68427|\n",
      "|        Berkeley|    California|        CA|          120971|       25000|\n",
      "|     Santa Clara|    California|        CA|          126216|       52281|\n",
      "+----------------+--------------+----------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the city data to spark dataframe\n",
    "city_df = spark.read.csv(\"us-cities-demographics.csv\",header=True,sep=\";\")\n",
    "\n",
    "# Clean City Demographics Data\n",
    "city_df = city_df.withColumn('Total Population', city_df['Male Population'] + city_df['Female Population'])\n",
    "city_df = city_df.withColumn(\"Total Population\", city_df[\"Total Population\"].cast(IntegerType()))\n",
    "city_df = city_df.where((col(\"Foreign-born\") <= col(\"Total Population\")) & (col(\"Number of Veterans\") <= col(\"Total Population\")))\n",
    "city_df = city_df.select('City', 'State', 'State Code', 'Total Population', 'Foreign-born')\n",
    "city_df = city_df.withColumnRenamed(\"Total Population\", \"Total_Population\")\n",
    "city_df.show()\n",
    "city_df.count() #2875 out of 2891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+----------------+------------+------------------+\n",
      "|            City|         State|State Code|Total_Population|Foreign-born|i94port_State_code|\n",
      "+----------------+--------------+----------+----------------+------------+------------------+\n",
      "|   Silver Spring|      Maryland|        MD|           82463|       30908|                MD|\n",
      "|          Quincy| Massachusetts|        MA|           93629|       32935|                MA|\n",
      "|          Hoover|       Alabama|        AL|           84839|        8229|                AL|\n",
      "|Rancho Cucamonga|    California|        CA|          175232|       33878|                CA|\n",
      "|          Newark|    New Jersey|        NJ|          281913|       86253|                NJ|\n",
      "|          Peoria|      Illinois|        IL|          118661|        7517|                IL|\n",
      "|        Avondale|       Arizona|        AZ|           80683|        8355|                AZ|\n",
      "|     West Covina|    California|        CA|          108489|       37038|                CA|\n",
      "|        O'Fallon|      Missouri|        MO|           85032|        3269|                MO|\n",
      "|      High Point|North Carolina|        NC|          109828|       16315|                NC|\n",
      "|          Folsom|    California|        CA|           76368|       13234|                CA|\n",
      "|          Folsom|    California|        CA|           76368|       13234|                CA|\n",
      "|    Philadelphia|  Pennsylvania|        PA|         1567442|      205339|                PA|\n",
      "|         Wichita|        Kansas|        KS|          389955|       40270|                KS|\n",
      "|         Wichita|        Kansas|        KS|          389955|       40270|                KS|\n",
      "|      Fort Myers|       Florida|        FL|           74015|       15365|                FL|\n",
      "|      Pittsburgh|  Pennsylvania|        PA|          304385|       28187|                PA|\n",
      "|          Laredo|         Texas|        TX|          255789|       68427|                TX|\n",
      "|        Berkeley|    California|        CA|          120971|       25000|                CA|\n",
      "|     Santa Clara|    California|        CA|          126216|       52281|                CA|\n",
      "+----------------+--------------+----------+----------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check that the state code of the city database is the same state code of the i94port \n",
    "\n",
    "@udf()\n",
    "def create_i94port(state_code):\n",
    "    '''\n",
    "    Input: State Code name form the I94 immigration data\n",
    "    Output: Corresponding State Code name as in the i94port.txt  \n",
    "    '''\n",
    "    list_statecode = list()\n",
    "    for val in i94port_cleaned.values():\n",
    "        list_statecode.append(val[-2:])\n",
    "        for element in list_statecode:\n",
    "            if state_code in element:\n",
    "                return element\n",
    "    \n",
    "# Add iport94 code based on city name\n",
    "city_df= city_df.withColumn(\"i94port_State_code\", create_i94port(city_df[\"State Code\"]))\n",
    "\n",
    "# Remove entries with no iport94 code\n",
    "city_df=city_df.filter(city_df.i94port_State_code != 'null')\n",
    "\n",
    "# Show results\n",
    "city_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------------+------------+------------------+-------+\n",
      "|        City|       State|State Code|Total_Population|Foreign-born|i94port_State_code|i94port|\n",
      "+------------+------------+----------+----------------+------------+------------------+-------+\n",
      "|      Newark|  New Jersey|        NJ|          281913|       86253|                NJ|    NEW|\n",
      "|      Peoria|    Illinois|        IL|          118661|        7517|                IL|    PIA|\n",
      "|Philadelphia|Pennsylvania|        PA|         1567442|      205339|                PA|    PHI|\n",
      "|      Laredo|       Texas|        TX|          255789|       68427|                TX|    LCB|\n",
      "|       Allen|Pennsylvania|        PA|          120207|       19652|                PA|    MCA|\n",
      "|     Suffolk|    Virginia|        VA|           88161|        2829|                VA|    FOK|\n",
      "|       Tulsa|    Oklahoma|        OK|          403091|       43751|                OK|    TUL|\n",
      "|     Seattle|  Washington|        WA|          684443|      119840|                WA|    SEA|\n",
      "|        Mesa|     Arizona|        AZ|          471833|       57492|                AZ|    OTM|\n",
      "|      Camden|  New Jersey|        NJ|           76131|       11317|                NJ|    CNJ|\n",
      "|  Alexandria|    Virginia|        VA|          153511|       44030|                VA|    AXB|\n",
      "|       Omaha|    Nebraska|        NE|          443887|       48263|                NE|    OMA|\n",
      "|       Omaha|    Nebraska|        NE|          443887|       48263|                NE|    OMA|\n",
      "|        Troy|    Michigan|        MI|           83276|       21004|                MI|    NRT|\n",
      "|     Atlanta|     Georgia|        GA|          463875|       32016|                GA|    ATL|\n",
      "|    Columbia|    Maryland|        MD|          103467|       23249|                MD|    CAE|\n",
      "|   Nashville|   Tennessee|        TN|          654596|       88193|                TN|    NSV|\n",
      "| Bakersfield|  California|        CA|          373627|       71575|                CA|    BFL|\n",
      "|  Huntsville|     Alabama|        AL|          189114|       12691|                AL|    HSV|\n",
      "|      Denver|    Colorado|        CO|          682545|      113222|                CO|    DEN|\n",
      "+------------+------------+----------+----------------+------------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter out the city names from the city database and returning the equivalent i94port of it\n",
    "\n",
    "@udf()\n",
    "def create_i94port(city):\n",
    "    '''\n",
    "    #Input: City name\n",
    "    #Output: Corresponding i94port (character code of destination city) \n",
    "    \n",
    "    '''\n",
    "    list_city = list()\n",
    "    for key, val in i94port_cleaned.items():\n",
    "        val = val.split(',')[0]\n",
    "        if city.lower() in val.lower():\n",
    "            return key\n",
    "    \n",
    "# Add iport94 code based on city name\n",
    "city_df= city_df.withColumn(\"i94port\", create_i94port(city_df[\"City\"]))\n",
    "#city_df= city_df.withColumn(\"i94port_city\", create_i94port(city_df[\"City\"]))\n",
    "# Remove entries with no iport94 code\n",
    "city_df=city_df.filter(city_df.i94port != 'null')\n",
    "\n",
    "# Show results\n",
    "city_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "I94 immigration data is the first dimension table with the following data:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = month in numbers\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination USA city\n",
    "* arrdate = arrival date in the USA\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date from the USA\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "\n",
    "The City Demographics Data is the second dimension table which contains the US cities with their population data. The following data were extracted from that data:\n",
    "* City = city name\n",
    "* State = Satate Name\n",
    "* Total_Population = total number of population in the city\n",
    "* Foreign-born = number of foreign born\n",
    "* i94port_State_code = ISO state code (mapped from immigration data during cleanup step)\n",
    "* i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "\n",
    "The fact table will contain information from the I94 immigration data joined with the City Demographics Data on i94port:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "* Total_Population = total number of population in the city\n",
    "* Foreign-born = number of foreign born\n",
    "*The tables will be saved to Parquet files partitioned by city (i94port).\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are described below:\n",
    "1. Clean I94 data as showed in step 2 to create Spark dataframe immigration_df for each month\n",
    "2. Clean City Demographics Data as showed in step 2 to create Spark dataframe city_df \n",
    "3. Create immigration dimension table and selecting related columns from immigration_df, and write to parquet file partitioned by i94port\n",
    "4. Create City Demographics Data by selecting related columns from city_df and write to parquet file partitioned by i94port\n",
    "5. Create fact table by joining immigration and city dimension tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to I94 immigration data \n",
    "immigration_data = '/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "immigration_df = clean_i94_data(immigration_data)\n",
    "\n",
    "# Extract columns for immigration dimension table\n",
    "immigration_table = immigration_df.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"])\n",
    "\n",
    "# parquet files partitioned by i94port for immigration table\n",
    "immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for temperature dimension table\n",
    "cities_table = city_df.select(['City', 'State', 'i94port_State_code', 'Total_Population','i94port', 'Foreign-born'])\n",
    "\n",
    "# Write temperature dimension table to parquet files partitioned by i94port\n",
    "cities_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/city.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration and city data\n",
    "immigration_df.createOrReplaceTempView(\"immigration_view\")\n",
    "city_df.createOrReplaceTempView(\"city_view\")\n",
    "\n",
    "# Create the fact table by joining the immigration and city views\n",
    "fact_table = spark.sql(\"\"\"\n",
    "SELECT immigration_view.i94yr as year,\n",
    "       immigration_view.i94mon as month,\n",
    "       immigration_view.i94cit as city,\n",
    "       immigration_view.i94port as i94port,\n",
    "       immigration_view.arrdate as arrival_date,\n",
    "       immigration_view.depdate as departure_date,\n",
    "       immigration_view.i94visa as reason,\n",
    "       city_view.Total_Population as population,\n",
    "       city_view.i94port_State_code as state_code\n",
    "       \n",
    "FROM immigration_view\n",
    "JOIN city_view ON (immigration_view.i94port = city_view.i94port)\n",
    "\"\"\")\n",
    "\n",
    "# Write fact table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for immigration_table is 2695274 records\n",
      "Data quality check for cities_table is 706 records\n"
     ]
    }
   ],
   "source": [
    "def quality_check(df, table_desciption):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram   \n",
    "    Output: Print outcome of data quality check\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} is zero record\".format(table_desciption))\n",
    "    else:\n",
    "        print(\"Data quality check for {} is {} records\".format(table_desciption, result))\n",
    "    #return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(immigration_df, \"immigration_table\")\n",
    "quality_check(city_df, \"cities_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "I94 immigration data of the US National Tourism and Trade Officeis the first dimension table with the following data:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = month in numbers\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "\n",
    "The City Demographics Data is the second dimension table which contains the US cities with their population data. The following data were extracted from that data:\n",
    "* City = city name\n",
    "* State = Satate Name\n",
    "* Total_Population = total number of population in the city\n",
    "* Foreign-born = number of foreign born\n",
    "* i94port_State_code = ISO state code (mapped from immigration data during cleanup step)\n",
    "* i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "\n",
    "The fact table will contain information from the I94 immigration data joined with the City Demographics Data on i94port:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "* Total_Population = total number of population in the city\n",
    "* Foreign-born = number of foreign born\n",
    "* The tables will be saved to Parquet files partitioned by city (i94port)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "Spark was chosen because it is one of the easiest tool that handles multiple file formats with large amounts of data. Spark SQL was chosen to process the large input files into dataframes and manipulated via standard SQL join operations to form additional tables.\n",
    "* Propose how often the data should be updated and why.\n",
    "The data should be updated in a monthly bases.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " 1. If the data was increased by 100x, we can consider moving Spark to cluster mode using a cluster manager.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " 2. We use Airflow to run the ETL pipeline.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " 3. There should be no problem with 100 or so people accessing this data, we can consider publishing the parquet files to HDFS and have a reading access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
